{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7229c3a0-ef52-4912-927e-929fc1eb94f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/97/h0rc_f714sq_pk21yjl72cgw0000gn/T/ipykernel_54030/23872536.py:15: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "#!pip install langchain\n",
    "#!pip install PyPDFLoader\n",
    "#!pip install langchainhub \n",
    "# ! pip install pypdf\n",
    "# ! pip install langchain_community\n",
    "# ! pip install langchain\n",
    "# ! pip install langchain_openai\n",
    "# ! pip install faiss-cpu\n",
    "# ! pip install langchainhub\n",
    "# ! pip install -U langchain-openai\n",
    "# ! pip install petl \n",
    "# ! pip install cdata\n",
    "# ! pip install elasticsearch-dsl\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ef7c6f1-dde4-43eb-b6d2-4f7acf5632f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'petl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# get data from elastic search\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpetl\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01metl\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# import cdata.elasticsearch as mod\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'petl'"
     ]
    }
   ],
   "source": [
    "# get data from elastic search\n",
    "import petl as etl\n",
    "import pandas as pd\n",
    "# import cdata.elasticsearch as mod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0aeaa00-0c6d-469f-a13d-29942810e1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: elasticsearch-dsl in /Users/felix_productive/jobSearch/braveCareer/swift_demo/chalice-env/lib/python3.9/site-packages (8.12.0)\n",
      "Requirement already satisfied: python-dateutil in /Users/felix_productive/jobSearch/braveCareer/swift_demo/chalice-env/lib/python3.9/site-packages (from elasticsearch-dsl) (2.8.2)\n",
      "Requirement already satisfied: elasticsearch<9.0.0,>=8.0.0 in /Users/felix_productive/jobSearch/braveCareer/swift_demo/chalice-env/lib/python3.9/site-packages (from elasticsearch-dsl) (8.12.1)\n",
      "Requirement already satisfied: elastic-transport<9,>=8 in /Users/felix_productive/jobSearch/braveCareer/swift_demo/chalice-env/lib/python3.9/site-packages (from elasticsearch<9.0.0,>=8.0.0->elasticsearch-dsl) (8.12.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/felix_productive/jobSearch/braveCareer/swift_demo/chalice-env/lib/python3.9/site-packages (from python-dateutil->elasticsearch-dsl) (1.16.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.2 in /Users/felix_productive/jobSearch/braveCareer/swift_demo/chalice-env/lib/python3.9/site-packages (from elastic-transport<9,>=8->elasticsearch<9.0.0,>=8.0.0->elasticsearch-dsl) (2.2.1)\n",
      "Requirement already satisfied: certifi in /Users/felix_productive/jobSearch/braveCareer/swift_demo/chalice-env/lib/python3.9/site-packages (from elastic-transport<9,>=8->elasticsearch<9.0.0,>=8.0.0->elasticsearch-dsl) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "! pip install elasticsearch-dsl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1c3fb24-1121-4f7f-b13f-0d37b70b6329",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = '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'\n",
    "\n",
    " \n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9ed0a86-ee07-48ad-8ed2-fc3be9edfee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felix_productive/jobSearch/braveCareer/swift_demo/chalice-env/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# get resume \n",
    "loader = PyPDFLoader(\"../data/Resume1.pdf\") \n",
    "\n",
    "pages = loader.load_and_split()\n",
    "faiss_index = FAISS.from_documents(pages, OpenAIEmbeddings())\n",
    "retriever = faiss_index.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "745a4607-8b1f-41bb-8a62-010d1d848179",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felix_productive/jobSearch/braveCareer/swift_demo/chalice-env/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "lm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\".join(doc.page_content for doc in docs)\n",
    "    \n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs,\n",
    "    \"question\": RunnablePassthrough() }\n",
    "    | prompt\n",
    "    | lm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8e65c5f-61d3-4eb0-b7e1-b148c206884e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Best Matching Job Positions: Full Stack Developer, Software Engineer, Cloud Infrastructure Developer\n",
      "- Top Skills: JavaScript, Python, Java, React, Redux, Jenkins, MongoDB\n",
      "- Industries: Tech\n",
      "- Years of Experience: Internship experience since 2021\n",
      "- Location: Various cities in the United States and Canada\n",
      "- Full Experience: Internships at Databricks, Pepperdata, SAP, Phonic AI, and Proving Grounds, with a focus on full stack development and cloud infrastructure.\n"
     ]
    }
   ],
   "source": [
    "s = rag_chain.invoke(\"\"\" Structure background by filling in the section below\n",
    "    - Best Matching Job Positions (for example \"Data Engineer\", \"Product Manager\", etc) rank from best fit to less fit:\n",
    "    - Top Skills he/she has (tile to 20):\n",
    "    - Industries (Like Retail, Tech, Consulting, Government, Finance, etc.):\n",
    "    - Years of Experience (estimate if not specified):\n",
    "    - Location (City, Country):\n",
    "    - Full Experience (including everything):\n",
    "   \"\"\"\n",
    ") \n",
    "\n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f61919e2-d158-4672-9f3f-9a37112ccc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The individual has experience with a variety of programming languages and technologies, including JavaScript, Python, Java, React, and MongoDB. They have completed internships at companies like Databricks, SAP, and Phonic AI, where they worked on tasks such as automating cloud resources, developing frontend features, and improving upload speeds. The individual also has experience with computer vision algorithms and gesture-based UI development.\n"
     ]
    }
   ],
   "source": [
    "s = rag_chain.invoke(f\"\"\" \n",
    "\n",
    "Given the resume \n",
    "   \"\"\"\n",
    ") \n",
    "\n",
    "print(s)\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06e1fb63-0be2-412f-bd1f-bc1eba48317e",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "# input_string = s\n",
    "\n",
    "# # Split the string into parts based on newline characters\n",
    "# parts = input_string.split('\\n')\n",
    "\n",
    "# # Initialize a dictionary to hold the column data\n",
    "# data_dict = {}\n",
    "\n",
    "# # Process each part of the string\n",
    "# for part in parts:\n",
    "#     # Split each part into key-value pairs based on the first colon found\n",
    "#     key, value = part.split(': ', 1)\n",
    "    \n",
    "#     # If there are multiple values separated by commas, split them into a list; otherwise, keep the value as is\n",
    "#     data_dict[key] = value.split(', ') if ', ' in value else value\n",
    "\n",
    "# # Convert the dictionary into a DataFrame\n",
    "# df = pd.DataFrame([data_dict])\n",
    "\n",
    "# # Display the DataFrame\n",
    "# df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b131cd0b-c8a5-46f4-95d9-ebf456aca5a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
