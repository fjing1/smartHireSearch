{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7229c3a0-ef52-4912-927e-929fc1eb94f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain\n",
    "#!pip install PyPDFLoader\n",
    "#!pip install langchainhub \n",
    "# ! pip install pypdf\n",
    "# ! pip install langchain_community\n",
    "# ! pip install langchain\n",
    "# ! pip install langchain_openai\n",
    "# ! pip install faiss-cpu\n",
    "# ! pip install langchainhub\n",
    "# ! pip install -U langchain-openai\n",
    "# ! pip install petl \n",
    "# ! pip install cdata\n",
    "# ! pip install elasticsearch-dsl\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ef7c6f1-dde4-43eb-b6d2-4f7acf5632f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'petl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# get data from elastic search\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpetl\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01metl\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'petl'"
     ]
    }
   ],
   "source": [
    "# get data from elastic search\n",
    "import petl as etl\n",
    "import pandas as pd\n",
    "# import cdata.elasticsearch as mod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0aeaa00-0c6d-469f-a13d-29942810e1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install elasticsearch-dsl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1c3fb24-1121-4f7f-b13f-0d37b70b6329",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = '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'\n",
    "\n",
    " \n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9ed0a86-ee07-48ad-8ed2-fc3be9edfee6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "pypdf package not found, please install it with `pip install pypdf`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/langchain/document_loaders/pdf.py:144\u001b[0m, in \u001b[0;36mPyPDFLoader.__init__\u001b[0;34m(self, file_path, password)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpypdf\u001b[39;00m  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pypdf'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# get resume \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m loader \u001b[38;5;241m=\u001b[39m \u001b[43mPyPDFLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/Resume1.pdf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[1;32m      4\u001b[0m pages \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mload_and_split()\n\u001b[1;32m      5\u001b[0m faiss_index \u001b[38;5;241m=\u001b[39m FAISS\u001b[38;5;241m.\u001b[39mfrom_documents(pages, OpenAIEmbeddings())\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/langchain/document_loaders/pdf.py:146\u001b[0m, in \u001b[0;36mPyPDFLoader.__init__\u001b[0;34m(self, file_path, password)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpypdf\u001b[39;00m  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    147\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpypdf package not found, please install it with \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install pypdf`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    148\u001b[0m     )\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparser \u001b[38;5;241m=\u001b[39m PyPDFParser(password\u001b[38;5;241m=\u001b[39mpassword)\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(file_path)\n",
      "\u001b[0;31mImportError\u001b[0m: pypdf package not found, please install it with `pip install pypdf`"
     ]
    }
   ],
   "source": [
    "# get resume \n",
    "loader = PyPDFLoader(\"../data/Resume1.pdf\") \n",
    "\n",
    "pages = loader.load_and_split()\n",
    "faiss_index = FAISS.from_documents(pages, OpenAIEmbeddings())\n",
    "retriever = faiss_index.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "745a4607-8b1f-41bb-8a62-010d1d848179",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felix_productive/jobSearch/braveCareer/swift_demo/chalice-env/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "lm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\".join(doc.page_content for doc in docs)\n",
    "    \n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs,\n",
    "    \"question\": RunnablePassthrough() }\n",
    "    | prompt\n",
    "    | lm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8e65c5f-61d3-4eb0-b7e1-b148c206884e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Best Matching Job Positions: Full Stack Developer, Software Engineer, Cloud Infrastructure Developer\n",
      "- Top Skills: JavaScript, Python, Java, React, Redux, Jenkins, MongoDB\n",
      "- Industries: Tech\n",
      "- Years of Experience: Internship experience since 2021\n",
      "- Location: Various cities in the United States and Canada\n",
      "- Full Experience: Internships at Databricks, Pepperdata, SAP, Phonic AI, and Proving Grounds, with a focus on full stack development and cloud infrastructure.\n"
     ]
    }
   ],
   "source": [
    "s = rag_chain.invoke(\"\"\" Structure background by filling in the section below\n",
    "    - Best Matching Job Positions (for example \"Data Engineer\", \"Product Manager\", etc) rank from best fit to less fit:\n",
    "    - Top Skills he/she has (tile to 20):\n",
    "    - Industries (Like Retail, Tech, Consulting, Government, Finance, etc.):\n",
    "    - Years of Experience (estimate if not specified):\n",
    "    - Location (City, Country):\n",
    "    - Full Experience (including everything):\n",
    "   \"\"\"\n",
    ") \n",
    "\n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f61919e2-d158-4672-9f3f-9a37112ccc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The individual has experience with a variety of programming languages and technologies, including JavaScript, Python, Java, React, and MongoDB. They have completed internships at companies like Databricks, SAP, and Phonic AI, where they worked on tasks such as automating cloud resources, developing frontend features, and improving upload speeds. The individual also has experience with computer vision algorithms and gesture-based UI development.\n"
     ]
    }
   ],
   "source": [
    "s = rag_chain.invoke(f\"\"\" \n",
    "Given the resume \n",
    "   \"\"\"\n",
    ") \n",
    "print(s)\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06e1fb63-0be2-412f-bd1f-bc1eba48317e",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "# input_string = s\n",
    "\n",
    "# # Split the string into parts based on newline characters\n",
    "# parts = input_string.split('\\n')\n",
    "\n",
    "# # Initialize a dictionary to hold the column data\n",
    "# data_dict = {}\n",
    "\n",
    "# # Process each part of the string\n",
    "# for part in parts:\n",
    "#     # Split each part into key-value pairs based on the first colon found\n",
    "#     key, value = part.split(': ', 1)\n",
    "    \n",
    "#     # If there are multiple values separated by commas, split them into a list; otherwise, keep the value as is\n",
    "#     data_dict[key] = value.split(', ') if ', ' in value else value\n",
    "\n",
    "# # Convert the dictionary into a DataFrame\n",
    "# df = pd.DataFrame([data_dict])\n",
    "\n",
    "# # Display the DataFrame\n",
    "# df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b131cd0b-c8a5-46f4-95d9-ebf456aca5a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
