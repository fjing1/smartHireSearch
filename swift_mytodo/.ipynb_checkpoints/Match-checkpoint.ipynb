{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7229c3a0-ef52-4912-927e-929fc1eb94f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain\n",
    "#!pip install PyPDFLoader\n",
    "#!pip install langchainhub \n",
    "# ! pip install pypdf\n",
    "# ! pip install langchain_community\n",
    "# ! pip install langchain\n",
    "# ! pip install langchain_openai\n",
    "# ! pip install faiss-cpu\n",
    "# ! pip install langchainhub\n",
    "# ! pip install -U langchain-openai\n",
    "# ! pip install petl \n",
    "# ! pip install cdata\n",
    "# ! pip install elasticsearch-dsl\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd67fd7e-977d-442a-8777-beb885f657fd",
   "metadata": {},
   "outputs": [],
   "source": [
    " #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ef7c6f1-dde4-43eb-b6d2-4f7acf5632f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data from elastic search\n",
    "import petl as etl\n",
    "import pandas as pd\n",
    "# import cdata.elasticsearch as mod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0aeaa00-0c6d-469f-a13d-29942810e1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting elasticsearch-dsl\n",
      "  Downloading elasticsearch_dsl-8.12.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: python-dateutil in /Users/kellyliu/anaconda3/lib/python3.11/site-packages (from elasticsearch-dsl) (2.8.2)\n",
      "Collecting elasticsearch<9.0.0,>=8.0.0 (from elasticsearch-dsl)\n",
      "  Downloading elasticsearch-8.12.1-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting elastic-transport<9,>=8 (from elasticsearch<9.0.0,>=8.0.0->elasticsearch-dsl)\n",
      "  Downloading elastic_transport-8.12.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/kellyliu/anaconda3/lib/python3.11/site-packages (from python-dateutil->elasticsearch-dsl) (1.16.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.2 in /Users/kellyliu/anaconda3/lib/python3.11/site-packages (from elastic-transport<9,>=8->elasticsearch<9.0.0,>=8.0.0->elasticsearch-dsl) (2.0.7)\n",
      "Requirement already satisfied: certifi in /Users/kellyliu/anaconda3/lib/python3.11/site-packages (from elastic-transport<9,>=8->elasticsearch<9.0.0,>=8.0.0->elasticsearch-dsl) (2024.2.2)\n",
      "Downloading elasticsearch_dsl-8.12.0-py3-none-any.whl (63 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/64.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading elasticsearch-8.12.1-py3-none-any.whl (432 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m432.1/432.1 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading elastic_transport-8.12.0-py3-none-any.whl (59 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: elastic-transport, elasticsearch, elasticsearch-dsl\n",
      "Successfully installed elastic-transport-8.12.0 elasticsearch-8.12.1 elasticsearch-dsl-8.12.0\n"
     ]
    }
   ],
   "source": [
    "! pip install elasticsearch-dsl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1c3fb24-1121-4f7f-b13f-0d37b70b6329",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kellyliu/anaconda3/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "os.environ['OPENAI_API_KEY'] = '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'\n",
    "\n",
    " \n",
    "# get resume \n",
    "loader = PyPDFLoader(\"./data/Kelly_Liu_Resume.pdf\") \n",
    "\n",
    "pages = loader.load_and_split()\n",
    "faiss_index = FAISS.from_documents(pages, OpenAIEmbeddings())\n",
    "retriever = faiss_index.as_retriever()\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "745a4607-8b1f-41bb-8a62-010d1d848179",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kellyliu/anaconda3/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "lm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\".join(doc.page_content for doc in docs)\n",
    "    \n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs,\n",
    "    \"question\": RunnablePassthrough() }\n",
    "    | prompt\n",
    "    | lm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8e65c5f-61d3-4eb0-b7e1-b148c206884e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Matching Job Positions: Data Scientist, Machine Learning Engineer, Fraud Analyst\n",
      "Top Skills: Python, SQL, PyTorch, Spark, Hadoop, AWS, Tableau, Machine Learning, Statistics, Neural Networks, Regression, SVM, PCA, K-means, Tree-based Models, Gradient Boosting\n",
      "Industries: Finance, Technology\n",
      "Years of Experience: 4 years\n",
      "Location: Canada, Toronto\n"
     ]
    }
   ],
   "source": [
    "s = rag_chain.invoke(\"\"\" Structure background by filling in the section below\n",
    "    - Best Matching Job Positions (for example \"Data Engineer\", \"Product Manager\", etc) rank from best fit to less fit:\n",
    "    - Top Skills he/she has (tile to 20):\n",
    "    - Industries (Like Retail, Tech, Consulting, Government, Finance, etc.):\n",
    "    - Years of Experience (estimate if not specified):\n",
    "    - Location (City, Country):\n",
    "    - Full Experience (including everything):\n",
    "   \"\"\"\n",
    ") \n",
    "\n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61919e2-d158-4672-9f3f-9a37112ccc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = rag_chain.invoke(f\"\"\" \n",
    "\n",
    "Given the resume \n",
    "   \"\"\"\n",
    ") \n",
    "\n",
    "print(s)\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "06e1fb63-0be2-412f-bd1f-bc1eba48317e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best Matching Job Positions</th>\n",
       "      <th>Top Skills</th>\n",
       "      <th>Industries</th>\n",
       "      <th>Years of Experience</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Data Scientist, Machine Learning Engineer, Fr...</td>\n",
       "      <td>[Python, SQL, PyTorch, Spark, Hadoop, AWS, Tab...</td>\n",
       "      <td>[Finance, Technology]</td>\n",
       "      <td>4 years</td>\n",
       "      <td>[Canada, Toronto]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Best Matching Job Positions  \\\n",
       "0  [Data Scientist, Machine Learning Engineer, Fr...   \n",
       "\n",
       "                                          Top Skills             Industries  \\\n",
       "0  [Python, SQL, PyTorch, Spark, Hadoop, AWS, Tab...  [Finance, Technology]   \n",
       "\n",
       "  Years of Experience           Location  \n",
       "0             4 years  [Canada, Toronto]  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "\n",
    "# input_string = s\n",
    "\n",
    "# # Split the string into parts based on newline characters\n",
    "# parts = input_string.split('\\n')\n",
    "\n",
    "# # Initialize a dictionary to hold the column data\n",
    "# data_dict = {}\n",
    "\n",
    "# # Process each part of the string\n",
    "# for part in parts:\n",
    "#     # Split each part into key-value pairs based on the first colon found\n",
    "#     key, value = part.split(': ', 1)\n",
    "    \n",
    "#     # If there are multiple values separated by commas, split them into a list; otherwise, keep the value as is\n",
    "#     data_dict[key] = value.split(', ') if ', ' in value else value\n",
    "\n",
    "# # Convert the dictionary into a DataFrame\n",
    "# df = pd.DataFrame([data_dict])\n",
    "\n",
    "# # Display the DataFrame\n",
    "# df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b131cd0b-c8a5-46f4-95d9-ebf456aca5a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
